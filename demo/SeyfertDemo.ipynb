{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "threatened-period",
   "metadata": {},
   "source": [
    "# SEYFERT Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-grave",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-andrew",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "t_begin = time.time()\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "from seyfert.utils import general_utils, filesystem_utils, formatters\n",
    "from seyfert.utils.tex_utils import TeXTranslator\n",
    "\n",
    "plt.style.use(\"plt_params.mplstyle\")\n",
    "\n",
    "from seyfert.config.forecast_config import ForecastConfig\n",
    "from seyfert.utils.workspace import WorkSpace\n",
    "from seyfert.cosmology import cosmology\n",
    "from seyfert.cosmology import redshift_density\n",
    "from seyfert.cosmology import c_ells\n",
    "\n",
    "from seyfert.main import cl_core\n",
    "from seyfert.main import cl_derivative_core\n",
    "from seyfert.main import fisher_core\n",
    "\n",
    "transl = TeXTranslator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-imperial",
   "metadata": {},
   "source": [
    "Logging: if you want full logs set do_full_log = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_full_log = False\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "if do_full_log:\n",
    "    general_utils.configure_logger(logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-suicide",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "\n",
    "SEYFERT configuration files are all written in JSON format, and are essentially of two types: \n",
    "\n",
    "* ForecastConfig: the master configuration for the forecast. It is associated to a ForecastConfig class defined in `seyfert/config/forecast_config.py`\n",
    "* MainConfig: the configuration for the main script do the single computation tasks, which are:\n",
    "    * computation of the power spectra;\n",
    "    * computation of the angular power spectra;\n",
    "    * computation of the derivatives of the angular power spectra;\n",
    "    * computation of the fisher matrices.\n",
    "\n",
    "First of all we do the workspace setup. The necessary input data are:\n",
    "\n",
    "* Configuration files: these are the above mentioned JSON files. Some example files are stored inside the directory `input/config`, and are written in the cell below.\n",
    "* Input data files: these are auxiliary files storing the configuration of galaxy redshift densities or galaxy bias. The example files are here stored in `input/data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = WorkSpace(\"rundir_test\")\n",
    "ws.run_dir.mkdir(exist_ok=True)\n",
    "\n",
    "input_data_dir = Path(\"input/data/\")\n",
    "\n",
    "src_input_files = {\n",
    "    'forecast': \"input/config/basic_forecast_config.json\",\n",
    "    'PowerSpectrum': \"input/config/power_spectrum_config.json\",\n",
    "    'Angular': \"input/config/angular_config.json\",\n",
    "    'Derivative': \"input/config/derivative_config.json\",\n",
    "    'Fisher': \"input/config/fisher_config.json\"\n",
    "}\n",
    "\n",
    "fcfg = ForecastConfig(input_file=src_input_files['forecast'], input_data_dir=input_data_dir)\n",
    "fcfg.loadPhysicalParametersFromJSONConfig()\n",
    "phys_pars = fcfg.phys_pars\n",
    "\n",
    "ws.createInputFilesDir(src_input_files=src_input_files, phys_pars=phys_pars, input_data_dir=input_data_dir)\n",
    "\n",
    "main_configs = ws.getTasksJSONConfigs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-belle",
   "metadata": {},
   "source": [
    "## Fiducial Cosmology\n",
    "\n",
    "In this forecast we work in a $w_0 w_a \\rm CDM$ flat cosmology, therefore the Hubble parameter is given by\n",
    "\n",
    "\\begin{equation}\n",
    "H(z)=H_{0} \\sqrt{\\Omega_{\\mathrm{m}}(1+z)^{3}+\\left(1-\\Omega_{\\mathrm{m}}\\right)(1+z)^{3\\left(1+w_{0}+w_{a}\\right)} \\exp \\left(-3 w_{a} \\frac{z}{1+z}\\right)}\n",
    "\\end{equation}\n",
    "\n",
    "In following cell the fiducial cosmology is loaded from file. Technically SEYFERT is also capable to call CAMB or CLASS to compute the matter power spectrum on the fly, but here in order to save time we load the already computed power spectra from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pmm_dir = Path(\"/ssd860/euclid_forecasts/spectrophoto/powerspectra/istf_pmms/\")\n",
    "pmm_dir = Path(\"/Users/lucapaganin/spectrophoto/powerspectra/istf_pmms/\")\n",
    "\n",
    "if not ws.pmm_dir.exists():\n",
    "    ws.symlinkToExternalDirs({\n",
    "        \"PowerSpectrum\": pmm_dir\n",
    "    })\n",
    "\n",
    "fid_cosmo = cosmology.Cosmology.fromHDF5(ws.getPowerSpectrumFile(dvar='central', step=0))\n",
    "fid_cosmo.evaluateOverRedshiftGrid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-pilot",
   "metadata": {},
   "source": [
    "## Redshift densities\n",
    "\n",
    "Here the redshift densities are computed and saved to disk.\n",
    "\n",
    "For $\\rm GC_{ph}$ we use the redbook theoretical density:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\mathrm{d} N^{\\mathrm{ph}}}{\\mathrm{d} z \\mathrm{~d} \\Omega}(z)=N_{0}^{\\mathrm{ph}}\\left(\\frac{z}{z_{0}}\\right)^{2} \\exp \\left[-\\left(\\frac{z}{z_{0}}\\right)^{3 / 2}\\right]\n",
    "\\end{equation}\n",
    "\n",
    "where $z_{0}=0.9 / \\sqrt{2}$ and the normalization factor $N_{0}^{\\mathrm{ph}}$ is chosen such that the surface densityof galaxies is equal to 30 galaxies per $\\rm arcmin^2$.\n",
    "\n",
    "For $\\rm GC_{sp}$ we employ the data from SPV2 which have been provided to use by Ben Granett.\n",
    "\n",
    "The *observed* galaxy densities are obtaining by \"convolving\" the theoretical distribution with a sort of gaussian probability (as done in IST:Forecast):\n",
    "\n",
    "\\begin{equation}\n",
    "n_{i}^{A}(z)=\n",
    "\\frac{\\int_{z_{i}^{-}}^{z_{i}^{+}} \\mathrm{d} z_{\\mathrm{p}} \\frac{\\mathrm{d} N^{A}}{\\mathrm{d} z \\mathrm{d} \\Omega}(z) p_{A}(z_{\\mathrm{p}} \\mid z)}{\\int_{z_{\\min }}^{z_{\\max }} \\mathrm{d} z \\int_{z_{i}^{-}}^{z_{i}^{+}} \\mathrm{d} z_{\\mathrm{p}} \\frac{\\mathrm{d} N^{A}}{\\mathrm{d} z \\mathrm{d} \\Omega}(z) p_{A}(z_{\\mathrm{p}} \\mid z)}\n",
    "\\end{equation}\n",
    "\n",
    "where $A$ stands for $\\rm GC_{ph}, GC_{sp}$ and $i$ is the tomographic bin index. The probability $p\\left(z_{\\mathrm{p}} \\mid z\\right)$ is parameterized as:\n",
    "\n",
    "\\begin{equation}\n",
    "p\\left(z_{\\mathrm{p}} \\mid z\\right)\n",
    "=\\frac{1-f_{\\text {out }}}{\\sqrt{2 \\pi} \\sigma_{\\mathrm{b}}(1+z)} \\exp \\left\\{-\\frac{1}{2}\\left[\\frac{z-c_{\\mathrm{b}} z_{\\mathrm{p}}-z_{\\mathrm{b}}}{\\sigma_{\\mathrm{b}}(1+z)}\\right]^{2}\\right\\}+\\frac{f_{\\text {out }}}{\\sqrt{2 \\pi} \\sigma_{\\mathrm{o}}(1+z)} \\exp \\left\\{-\\frac{1}{2}\\left[\\frac{z-c_{0} z_{\\mathrm{p}}-z_{0}}{\\sigma_{\\mathrm{o}}(1+z)}\\right]^{2}\\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "The parameters used for $p\\left(z_{\\mathrm{p}} \\mid z\\right)$ are reported in the following table:\n",
    "\n",
    "| probe                       |  $c_{\\mathrm{b}}$    |  $z_{\\mathrm{b}}$    |  $\\sigma_{\\mathrm{b}}$    |  $c_{\\mathrm{o}}$    |  $z_{\\mathrm{o}}$    |  $\\sigma_{\\mathrm{o}}$    |  $f_{\\mathrm{out}}$   |\n",
    "|:----------------------------|:---------------------|:---------------------|:--------------------------|:---------------------|:---------------------|:--------------------------|:----------------------|\n",
    "| $\\mathrm{GC}_{\\mathrm{ph}}$ | $1.0$                | $0.0$                | $0.050$                   | $1.0$                | $0.1$                | $0.05$                    | $0.1$                 |\n",
    "| $\\mathrm{GC}_{\\mathrm{sp}}$ | $1.0$                | $0.0$                | $0.001$                   | $-$                  | $-$                  | $-$                       | $-$                   |\n",
    "\n",
    "\n",
    "Now let's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ws.niz_file.is_file():\n",
    "    densities = {\n",
    "        \"Lensing\": redshift_density.RedshiftDensity.fromHDF5(\"input/data/WL/gcph_dndz_redbook.h5\"),\n",
    "        \"PhotometricGalaxy\": redshift_density.RedshiftDensity.fromHDF5(\"input/data/GCph/gcph_dndz_redbook.h5\"),\n",
    "        \"SpectroscopicGalaxy\": redshift_density.RedshiftDensity.fromHDF5(\"input/data/GCsp/gcsp_dndz_4_bins.h5\")\n",
    "    }\n",
    "    for probe in densities:\n",
    "        densities[probe].setUp()\n",
    "        densities[probe].evaluate(z_grid=fid_cosmo.z_grid)\n",
    "        densities[probe].evaluateSurfaceDensity()\n",
    "\n",
    "    redshift_density.save_densities_to_file(densities=densities, file=ws.niz_file)\n",
    "else:\n",
    "    densities = redshift_density.load_densities_from_file(file=ws.niz_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-jamaica",
   "metadata": {},
   "source": [
    "### Photo-z densities\n",
    "\n",
    "Here we plot the $\\rm GC_{ph}$ galaxy densities. The tomographic bins used are 10 equi-populated bins in the range $z \\in [0.001, 2.5]$. The bin edges are the following\n",
    "\n",
    "\\begin{equation}\n",
    "z_{i}=\\{0.0010,0.42,0.56,0.68,0.79,0.90,1.02,1.15,1.32,1.58,2.50\\}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "nph = densities[\"PhotometricGalaxy\"]\n",
    "\n",
    "for i in range(nph.n_bins):\n",
    "    plt.plot(nph.z_grid, nph.norm_density_iz[i], label=f'{i+1}')\n",
    "\n",
    "plt.xlabel(\"$z$\", fontsize=22)\n",
    "plt.legend(bbox_to_anchor=[1, 0.38], title=\"bin index\")\n",
    "plt.title(r\"$\\rm GC_{ph}$\")\n",
    "    \n",
    "del nph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-value",
   "metadata": {},
   "source": [
    "### Spectro-z densities\n",
    "\n",
    "Here we plot the $\\rm GC_{sp}$ galaxy densities. The baseline tomographic bins used for spectro-z are the 4 bins used for the power spectrum analysis of IST:F\n",
    "\n",
    "\\begin{equation}\n",
    "z_{i} = \\{0.9, 1.1, 1.3, 1.5, 1.8\\}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsp = densities[\"SpectroscopicGalaxy\"]\n",
    "\n",
    "for i in range(nsp.n_bins):\n",
    "    plt.plot(nsp.z_grid, nsp.norm_density_iz[i], label=f'{i+1}')\n",
    "\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(bbox_to_anchor=[1, 0.70], title=\"bin index\")\n",
    "plt.title(r\"$\\rm GC_{sp}$\")\n",
    "    \n",
    "del nsp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-duncan",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-shelter",
   "metadata": {},
   "source": [
    "## Angular power spectra\n",
    "\n",
    "### Limber approximation\n",
    "\n",
    "Here the $C(\\ell)$'s in the reference cosmology are evaluated. The Limber approximation is used to compute the $C(\\ell)$'s:\n",
    "\n",
    "\\begin{equation}\n",
    "C^{AB}_{ij}(\\ell) \\simeq \\frac{c}{H_0} \\int_{z_\\mathrm{min}}^{z_\\mathrm{max}} \\mathrm{d} z \n",
    "\\frac{W_{i}^{A}(z) W_{j}^{B}(z)}{E(z) \\chi^{2}(z)} P_{\\delta\\delta}\\left[ k=\\frac{\\ell+1/2}{r(z)}, z \\right]\n",
    "\\end{equation}\n",
    "\n",
    "where $\\chi(z)$ is the comoving distance and $E(z)$ is the dimensionless Hubble parameter. \n",
    "\n",
    "### Weight functions for galaxy clustering\n",
    "\n",
    "For galaxy clustering the weight functions are defined by\n",
    "\n",
    "\\begin{equation}\n",
    "W^{\\mathrm{A}}_i(z) = b^{\\mathrm{A}}(z) \\frac{H(z)}{c} n^{\\mathrm{A}}_{i}(z)\\, \\qquad \\mathrm{A} = \\mathrm{GC_{ph}}, \\mathrm{GC_{sp}}\n",
    "\\end{equation}\n",
    "\n",
    "The galaxy bias is assumed to be a step piecewise function. The photometric bias is computed as in IST:F\n",
    "\n",
    "\\begin{equation}\n",
    "b^{\\mathrm{ph}}(z) = b^{\\mathrm{ph}}_i = \\sqrt{1 + \\bar{z}_i}, \\quad \\text{when} \\quad z_i^- < z < z_i^+ \\quad \\text{and} \\quad \\bar{z}_i = \\frac{z_i^- + z_i^+}{2}\n",
    "\\end{equation}\n",
    "\n",
    "The spectroscopic bias is the same used for the IST:F Fourier power spectrum analysis. The bias values in the 4 spectroscopic bins are\n",
    "\n",
    "\\begin{equation}\n",
    "b^{\\mathrm{sp}}_i = \\{1.46, 1.61, 1.75, 1.90 \\}\n",
    "\\end{equation}\n",
    "\n",
    "### Weight function for weak lensing\n",
    "\n",
    "For cosmic shear the weight function is\n",
    "\n",
    "\\begin{equation}\n",
    "W_i^\\gamma(z) = \n",
    "\\frac{3}{2}\\left(\\frac{H_{0}}{c}\\right)^{2} \\Omega_{\\rm m}(1+z) \\chi(z) \\int_{z}^{z_{\\rm max}} \\mathrm{d} z'\\, n^{\\rm ph}_{i}(z')\\left[1 - \\frac{\\chi(z)}{\\chi(z')}\\right]\\, .\n",
    "\\end{equation}\n",
    "\n",
    "Introducing the intrinsic alignment contribution we obtain the weak lensing weight function:\n",
    "\n",
    "\\begin{equation}\n",
    "W_{i}^{\\rm wl}(z) = W_{i}^{\\gamma}(z) - \\mathcal{A}_{\\mathrm{IA}} C_{\\mathrm{IA}} \\Omega_{\\rm m} \\frac{H(z)\\mathcal{F}_{\\rm IA}(z)}{c D(z)} n^{\\rm ph}_{i}(z)\\, .\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sweet-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.cl_dir.mkdir(exist_ok=True)\n",
    "\n",
    "fid_cl_file = ws.cl_dir / \"dvar_central_step_0\" / \"cls_fiducial.h5\"\n",
    "\n",
    "if not fid_cl_file.is_file():\n",
    "\n",
    "    fid_cls = cl_core.compute_cls(cosmology=fid_cosmo, phys_pars=phys_pars, densities=densities, \n",
    "                                  forecast_config=fcfg, angular_config=main_configs['Angular'])\n",
    "\n",
    "    fid_cl_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    fid_cls.saveToHDF5(fid_cl_file)\n",
    "else:\n",
    "    fid_cls = c_ells.AngularCoefficientsCollector.fromHDF5(fid_cl_file)\n",
    "\n",
    "del fid_cl_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-cattle",
   "metadata": {},
   "source": [
    "### Plot the weight functions\n",
    "\n",
    "Here we plot the weight functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seyfert.plot_utils.cl_plot import plot_weight_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874022a6-d466-4e0a-9a6b-d840b7bdbe51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f163868-8bc7-47f0-83b6-1ef07543600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weight_funcs(fid_cls, cosmo=fid_cosmo, phys_pars=phys_pars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a5be5b-88a2-49ba-bbb9-6d1beca92396",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c708594-dfe0-4238-af2f-19b62f8c5cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "seven-incidence",
   "metadata": {},
   "source": [
    "### Plot auto-correlation angular power spectra\n",
    "\n",
    "Here we plot the diagonals of the auto-correlations $C(\\ell)$'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in ['phph', 'spsp', 'wlwl']:\n",
    "    fig = plt.figure()\n",
    "    cl = fid_cls[kind]\n",
    "    ells = cl.l_bin_centers\n",
    "\n",
    "    for i in range(cl.n_i):\n",
    "        plt.loglog(ells, ells*(ells+1)*cl.c_lij[:, i, i], label=i)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=[1.0, 0.4], title=\"bin index\")\n",
    "    plt.title(r\"$C^{\\rm %s}_{ii}(\\ell)$\" % kind)\n",
    "    plt.xlabel(r\"$\\ell$\", fontsize=22)\n",
    "    plt.ylabel(r\"$\\ell (\\ell+1) C(\\ell)$\", fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-sellers",
   "metadata": {},
   "source": [
    "## Derivatives of angular power spectra\n",
    "\n",
    "Compute $C(\\ell)$ derivatives with respect to the free parameters, which may be cosmological or nuisance. The derivatives are computed with the SteM® algorithm (credits to Stefano Camera).\n",
    "\n",
    "\n",
    "First of all set the free parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "#free_pars = [\"w0\", \"wa\", \"Omm\"]\n",
    "free_pars = list(phys_pars.free_physical_parameters.keys())\n",
    "\n",
    "for name in phys_pars:\n",
    "    if name not in free_pars:\n",
    "        phys_pars[name].is_free_parameter = False\n",
    "    else:\n",
    "        phys_pars[name].is_free_parameter = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-practice",
   "metadata": {},
   "source": [
    "Do the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-magnet",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ws.der_dir.mkdir(exist_ok=True)\n",
    "cl_ders_file = ws.der_dir / \"cl_ders.pickle\"\n",
    "\n",
    "if not cl_ders_file.is_file():\n",
    "    data = {\n",
    "        \"fid_cls\": fid_cls,\n",
    "        \"ws\": ws,\n",
    "        \"phys_pars\": phys_pars,\n",
    "        \"densities\": densities,\n",
    "        \"forecast_config\": fcfg,\n",
    "        \"angular_config\": main_configs['Angular'],\n",
    "        \"fiducial_cosmology\": fid_cosmo\n",
    "    }\n",
    "    \n",
    "    ti = time.time()\n",
    "    ders_dict = {}\n",
    "    n_params = len(free_pars)\n",
    "\n",
    "    for i, dvar in enumerate(phys_pars.free_physical_parameters):\n",
    "        t1 = time.time()\n",
    "        print(f\"{'#'*40} Computing cl derivatives w.r.t. {dvar}: {i+1}/{n_params} {'#'*40}\")\n",
    "        ders_dict[dvar] = cl_derivative_core.compute_cls_derivatives_wrt(dvar, **data)\n",
    "        t2 = time.time()\n",
    "        print(f\"Elapsed time: {formatters.string_time_format(t2 - t1)}\")\n",
    "\n",
    "\n",
    "    tf = time.time()\n",
    "    print(\"\")\n",
    "    print(f\"Cl derivatives total elapsed time: {formatters.string_time_format(tf - ti)}\")\n",
    "\n",
    "    with open(cl_ders_file, mode=\"wb\") as f:\n",
    "        pickle.dump(ders_dict, f)\n",
    "else:\n",
    "    with open(cl_ders_file, mode=\"rb\") as f:\n",
    "        ders_dict = pickle.load(f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-geography",
   "metadata": {},
   "source": [
    "### Plot of derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcl_phph = ders_dict['w0'].dcl_dict['PhotometricGalaxy_PhotometricGalaxy']\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(dcl_phph.l_bin_centers, dcl_phph.dc_lij[:, i, i], label=i+1)\n",
    "\n",
    "plt.legend(bbox_to_anchor=[1.0, 0.4], title=\"bin index\")\n",
    "plt.title(r\"Derivative of $C^{\\rm phph}_{ii}(\\ell)$ w.r.t. to $w_0$\")\n",
    "plt.xscale('log')\n",
    "plt.xlabel(r\"$\\ell$\", fontsize=22)\n",
    "plt.ylabel(r\"$\\frac{\\partial C^{\\rm phph}_{ii}(\\ell)}{\\partial w_0}$\", rotation=0, fontsize=22, labelpad=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-spirituality",
   "metadata": {},
   "source": [
    "## Compute and save Delta Cls\n",
    "\n",
    "Compute the $\\Delta C(\\ell)$'s. These are simply defined as\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta C^{AB}_{ij}(\\ell) = \\frac{1}{\\sqrt{f_{\\rm sky}\\Delta\\ell}} \\left[ C^{AB}_{ij}(\\ell) + N^{AB}_{ij}(\\ell) \\right]\n",
    "\\end{equation}\n",
    "\n",
    "where $N^{AB}_{ij}(\\ell)$ is the Poisson shot noise, and $f_{\\rm sky}$ is the sky fraction covered by Euclid. The sky fraction is computed assuming an observed sky area of $15000 \\, \\mathrm{deg}^2$, and therefore since the full sky is approximately $41252.961 \\, \\mathrm{deg}^2$ we have\n",
    "\n",
    "\\begin{equation}\n",
    "f_{\\rm sky} \\simeq 0.36361\n",
    "\\end{equation}\n",
    "\n",
    "The covariance matrix for the $C(\\ell)$'s is calculated as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{Cov}[ C^{AB}_{ij}(\\ell), C^{CD}_{km}(\\ell')] = \\frac{\\delta_{\\ell\\ell'}^{\\rm K}}{2\\ell + 1} \n",
    "\\left[\n",
    "\\Delta C^{AC}_{ij}(\\ell)\\Delta C^{BD}_{ij}(\\ell') + \\Delta C^{AD}_{ij}(\\ell) \\Delta C^{BC}_{ij}(\\ell')\n",
    "\\right]\n",
    "\\end{equation}\n",
    "\n",
    "where $\\delta_{\\ell\\ell'}^{\\rm K}$ is the Kronecker delta.\n",
    "\n",
    "The following cell computes and saves on disk the $\\Delta C^{AB}(\\ell)$'s for each combination of the probe indices $A$ and $B$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ws.delta_cls_file.is_file():\n",
    "    delta_cls = cl_core.compute_delta_cls(ws)\n",
    "    delta_cls.saveToHDF5(ws.delta_cls_file)\n",
    "else:\n",
    "    delta_cls = cl_core.DeltaClCollection.fromHDF5(ws.delta_cls_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-jaguar",
   "metadata": {},
   "source": [
    "## Fisher\n",
    "\n",
    "### Theory\n",
    "Here we compute the Fisher matrices. The formula for the computation of the Fisher matrix is\n",
    "\n",
    "\\begin{equation}\n",
    "F_{\\alpha \\beta} = \n",
    "\\sum_{\\ell = \\ell_{\\rm min}}^{\\ell_{\\rm max}}\n",
    "\\frac{\\partial \\mathbf{C}(\\ell)^{T}}{\\partial \\theta_{\\alpha}} \\mathrm{Cov}[\\mathbf{C}(\\ell), \\mathbf{C}(\\ell)]^{-1} \\frac{\\partial \\mathbf{C}(\\ell)}{\\partial \\theta_{\\beta}}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{C}(\\ell)$ is the datavector containing the angular power spectra involved in the computation of the Fisher matrix. Since the $C(\\ell)$'s are matrices, it is necessary to turn them into vectors using $\\mathrm{vecp}$ or $\\mathrm{vec}$ depending on whether they are symmetric (auto-correlations) or not. \n",
    "As an example, if one wants to compute the Fisher matrix $[\\mathrm{WL}+\\mathrm{GC_{ph}}+\\mathrm{XC}(\\mathrm{WL},\\mathrm{GC_{ph}})]$ the data-vector will be the following:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{C}(\\ell) = \\left\\{\\mathbf{C}^{\\rm wlwl}(\\ell), \\mathbf{C}^{\\rm phph}(\\ell), \\mathbf{C}^{\\rm wlph}(\\ell)\\right\\}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\rm wl \\equiv WL$ and $\\rm ph \\equiv GC_{ph}$. The corresponding covariance matrix is a block matrix with the following layout:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathrm{Cov}[\\mathbf{C}(\\ell), \\mathbf{C}(\\ell)]=\n",
    "\\left(\\begin{array}{lll}\n",
    "\\mathrm{Cov}\\left[\\mathbf{C}^{\\mathrm{wlwl}}(\\ell), \\mathbf{C}^{\\mathrm{wlwl}}(\\ell)\\right] & \n",
    "\\mathrm{Cov}\\left[\\mathbf{C}^{\\mathrm{wlwl}}(\\ell), \\mathbf{C}^{\\mathrm{phph}}(\\ell)\\right] & \n",
    "\\mathrm{Cov}\\left[\\mathbf{C}^{\\mathrm{wlwl}}(\\ell), \\mathbf{C}^{\\mathrm{wlph}}(\\ell)\\right] \\\\\n",
    "\\mathrm{Cov}\\left[\\mathbf{C}^{\\mathrm{phph}}(\\ell), \\mathbf{C}^{\\mathrm{wlwl}}(\\ell)\\right] & \n",
    "\\mathrm{Cov}\\left[\\mathbf{C}^{\\mathrm{phph}}(\\ell), \\mathbf{C}^{\\mathrm{phph}}(\\ell)\\right] & \n",
    "\\mathrm{Cov}\\left[\\mathbf{C}^{\\mathrm{phph}}(\\ell), \\mathbf{C}^{\\mathrm{wlph}}(\\ell)\\right] \\\\\n",
    "\\mathrm{Cov}\\left[\\mathbf{C}^{\\mathrm{wlph}}(\\ell), \\mathbf{C}^{\\mathrm{wlwl}}(\\ell)\\right] & \n",
    "\\mathrm{Cov}\\left[\\mathbf{C}^{\\mathrm{wlph}}(\\ell), \\mathbf{C}^{\\mathrm{phph}}(\\ell)\\right] & \n",
    "\\mathrm{Cov}\\left[\\mathbf{C}^{\\mathrm{wlph}}(\\ell), \\mathbf{C}^{\\mathrm{wlph}}(\\ell)\\right]\n",
    "\\end{array}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "### Implementation\n",
    "\n",
    "The needed input data for the computation are:\n",
    "\n",
    "* the physical parameters involved in the forecast;\n",
    "* the $\\Delta C^{AB}(\\ell)$'s;\n",
    "* the derivatives of the $C^{AB}(\\ell)$ for the free parameters of the forecast.\n",
    "\n",
    "Also the **datavectors** for the Fisher computation must be specified. With datavector here we mean the information about which $C(\\ell)$ are to be inserted in the particular Fisher matrix computation, with the definition given above. The representation of the datavector is given by strings separated by underscores. \n",
    "\n",
    "Here as an example we calculate the following Fisher matrices:\n",
    "\n",
    "* $[\\mathrm{WL}]$: `wlwl`;\n",
    "* $[\\mathrm{GC_{ph}}]$: `phph`;\n",
    "* $[\\mathrm{WL}+\\mathrm{GC_{ph}}]$: `wlwl_phph`;\n",
    "* $[\\mathrm{WL}+\\mathrm{GC_{ph}}+\\mathrm{XC}(\\mathrm{WL},\\mathrm{GC_{ph}})]$: `wlwl_phph_wlph`.\n",
    "\n",
    "The square brackets serves to identify the datavector extent. Hence with $[\\mathrm{WL}+\\mathrm{GC_{ph}}]$ we mean to combine the two probes *keeping the cross-covariance into account*.\n",
    "\n",
    "Let's start the computation. First of all we compute the auto-correlation fishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.base_fishers_dir.mkdir(exist_ok=True)\n",
    "\n",
    "fisher_input_data = {\n",
    "    \"outdir\": ws.base_fishers_dir,\n",
    "    \"ws\": ws,\n",
    "    \"phys_pars\": phys_pars,\n",
    "    \"delta_cls\": delta_cls,\n",
    "    \"dcoll_dvar_dict\": ders_dict\n",
    "}\n",
    "\n",
    "auto_fishers = fisher_core.compute_and_save_fishers([\"phph\", \"spsp\", \"wlwl\"], ws.base_fishers_dir, ws, phys_pars, delta_cls, ders_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-rwanda",
   "metadata": {},
   "source": [
    "Now compute some combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decimal-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_str_datavectors = [\n",
    "    \"wlwl_phph\", \"wlwl_phph_wlph\", \n",
    "    \"phph_spsp\", \"phph_spsp_phsp\",\n",
    "    \"wlwl_spsp\", \"wlwl_spsp_wlsp\",\n",
    "    \"wlwl_phph_wlph_spsp\",\n",
    "    \"wlwl_phph_wlph_spsp_wlsp\",\n",
    "    \"wlwl_phph_wlph_spsp_phsp\",\n",
    "    \"wlwl_phph_wlph_spsp_wlsp_phsp\",\n",
    "]\n",
    "\n",
    "fishers = fisher_core.compute_and_save_fishers(brief_str_datavectors, ws.base_fishers_dir, ws, phys_pars, delta_cls, ders_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-singer",
   "metadata": {},
   "source": [
    "Load IST:F Pk fisher matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seyfert.fisher.fisher_matrix import FisherMatrix\n",
    "\n",
    "f_gcsp_pk = FisherMatrix.from_ISTfile(filesystem_utils.get_ist_gcsp_pk_fisher_file(\"optimistic\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-explanation",
   "metadata": {},
   "source": [
    "## Some contour plots\n",
    "\n",
    "Plot Fisher contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-branch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seyfert.fisher.fisher_analysis import FisherAnalysis\n",
    "from seyfert.fisher.fisher_plot import FisherPlotter\n",
    "\n",
    "full_analysis = FisherAnalysis.fromFishersDir(ws.base_fishers_dir, params=phys_pars)\n",
    "\n",
    "full_analysis.fisher_matrices.update({\n",
    "    \"[GCsp(Pk)]\": f_gcsp_pk\n",
    "})\n",
    "\n",
    "cmap = matplotlib.colors.ListedColormap([\"dodgerblue\", \"forestgreen\", \"gold\"])\n",
    "pars_to_plot=[\"Omm\", \"h\", \"w0\", \"wa\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-nation",
   "metadata": {},
   "source": [
    "### WLxGCph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "wlph_analysis = full_analysis.getSubsetAnalysis([\"[WL]\", \"[WL+GCph]\", \"[WL+GCph+XC(WL,GCph)]\"])\n",
    "wlph_analysis.evaluateMarginalizedErrors()\n",
    "wlph_analysis.name = \"WLxGCph\"\n",
    "\n",
    "plotter = FisherPlotter(pars_to_plot=pars_to_plot, fisher_analysis=wlph_analysis)\n",
    "plotter.setPlotConfig(config_file=\"input/config/results_config.json\")\n",
    "plotter.setParametersPlotRanges()\n",
    "plotter.config.cmap = cmap\n",
    "\n",
    "fig, axs = plotter.makeTriangularPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hindu-palmer",
   "metadata": {},
   "source": [
    "### WLxGCsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "phsp_analysis = full_analysis.getSubsetAnalysis([\"[WL]\", \"[WL+GCsp]\", \"[WL+GCsp+XC(WL,GCsp)]\"])\n",
    "phsp_analysis.evaluateMarginalizedErrors()\n",
    "phsp_analysis.name = \"WLxGCsp\"\n",
    "\n",
    "plotter = FisherPlotter(pars_to_plot=pars_to_plot, fisher_analysis=phsp_analysis)\n",
    "plotter.setPlotConfig(config_file=\"input/config/results_config.json\")\n",
    "plotter.setParametersPlotRanges()\n",
    "plotter.config.cmap = cmap\n",
    "\n",
    "fig, axs = plotter.makeTriangularPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-trust",
   "metadata": {},
   "source": [
    "### 6x2pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "sixtwopt_analysis = full_analysis.getSubsetAnalysis([\n",
    "    '[WL+GCph+XC(WL,GCph)]',\n",
    "    '[WL+GCph+XC(WL,GCph)+GCsp]',\n",
    "    '[WL+GCph+XC(WL,GCph)+GCsp+XC(WL,GCsp)]',\n",
    "    '[WL+GCph+XC(WL,GCph)+GCsp+XC(GCph,GCsp)]',\n",
    "    '[WL+GCph+XC(WL,GCph)+GCsp+XC(WL,GCsp)+XC(GCph,GCsp)]'\n",
    "])\n",
    "\n",
    "sixtwopt_analysis.evaluateMarginalizedErrors()\n",
    "sixtwopt_analysis.name = \"6x2pt\"\n",
    "\n",
    "plotter = FisherPlotter(pars_to_plot=pars_to_plot, fisher_analysis=sixtwopt_analysis)\n",
    "plotter.setPlotConfig(config_file=\"input/config/results_config.json\")\n",
    "plotter.setParametersPlotRanges()\n",
    "\n",
    "fig, axs = plotter.makeTriangularPlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_end = time.time()\n",
    "\n",
    "print(f\"Total notebook run time: {formatters.string_time_format(t_end - t_begin)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-traffic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-swimming",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-think",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
